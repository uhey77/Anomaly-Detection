import os
import gradio as gr
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
import time
import yfinance as yf
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import *

# ç•°å¸¸æ¤œçŸ¥å™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from detection.anomaly_detector import AnomalyDetector

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.data_utils import load_sample_data, save_sample_data, load_multi_indicator_data

# LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.llm_clients import OpenAIClient, HuggingFaceClient, MockLLMClient

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from agents.web_agent import WebInformationAgent
from agents.knowledge_agent import KnowledgeBaseAgent
from agents.crosscheck_agent import CrossCheckAgent
from agents.report_agent import ReportIntegrationAgent
from agents.manager_agent import ManagerAgent

# è©•ä¾¡ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from evaluation import AnomalyEvaluator

# ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆå™¨ã¨äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.signal_generator import SignalGenerator
from models.time_series_models import LSTMModel, TimesFMModel
from models.forecasting_pipeline import ForecastingPipeline

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from realtime_data_provider import RealTimeDataProvider
    REALTIME_AVAILABLE = True
    print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError:
    REALTIME_AVAILABLE = False
    print("âš ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# DataManagerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from utils.data_utils import DataManager
    data_manager = DataManager()
    rt_provider = RealTimeDataProvider() if REALTIME_AVAILABLE else None
    print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
except ImportError:
    print("âš ï¸ DataManagerã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    data_manager = None
    rt_provider = None


# ä¿®æ­£ç‰ˆSignalGeneratorã‚¯ãƒ©ã‚¹ï¼ˆãƒ‡ãƒ¼ã‚¿å‹å•é¡Œå¯¾å¿œï¼‰
class FixedSignalGenerator:
    """ç•°å¸¸æ¤œçŸ¥çµæœã‹ã‚‰å£²è²·ã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆãƒ‡ãƒ¼ã‚¿å‹å•é¡Œä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self, threshold=0.5, window_size=5):
        self.threshold = threshold
        self.window_size = window_size
        
    def generate_signals(self, df, anomalies):
        """ç•°å¸¸æ¤œçŸ¥çµæœã‹ã‚‰å£²è²·ã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆ"""
        signals_df = df.copy()
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’çµ±ä¸€ï¼ˆfloat64ã«ï¼‰
        if 'Close' in signals_df.columns:
            signals_df['Close'] = signals_df['Close'].astype(np.float64)
        
        signals_df['signal'] = 0
        signals_df['anomaly_score'] = np.float64(0.0)
        
        if 'pct_change' not in signals_df.columns:
            signals_df['pct_change'] = signals_df['Close'].pct_change() * 100
        
        signals_df['pct_change'] = signals_df['pct_change'].astype(np.float64)
        
        if not anomalies.empty:
            for idx, anomaly in anomalies.iterrows():
                date = anomaly['Date']
                
                try:
                    matching_rows = signals_df[signals_df['Date'] == date]
                    if matching_rows.empty:
                        continue
                    
                    df_idx = matching_rows.index[0]
                    
                    if df_idx >= self.window_size:
                        past_data = signals_df.loc[df_idx-self.window_size:df_idx-1, 'Close']
                        if len(past_data) > 1:
                            past_trend = past_data.pct_change().mean()
                        else:
                            past_trend = 0.0
                        
                        if 'pct_change' in anomaly:
                            current_change = float(anomaly['pct_change']) / 100
                        else:
                            if df_idx > 0:
                                prev_price = float(signals_df.loc[df_idx-1, 'Close'])
                                curr_price = float(anomaly['Close'])
                                current_change = (curr_price - prev_price) / prev_price
                            else:
                                current_change = 0.0
                        
                        if 'z_score' in anomaly:
                            anomaly_score = abs(float(anomaly['z_score']))
                        elif 'anomaly_score' in anomaly:
                            anomaly_score = abs(float(anomaly['anomaly_score']))
                        else:
                            anomaly_score = abs(current_change) / 0.01
                        
                        trend_threshold = 1.5
                        if current_change > 0 and (current_change > past_trend * trend_threshold):
                            signals_df.loc[df_idx, 'signal'] = 1
                        elif current_change < 0 and (current_change < past_trend * trend_threshold):
                            signals_df.loc[df_idx, 'signal'] = -1
                        
                        signals_df.loc[df_idx, 'anomaly_score'] = np.float64(anomaly_score)
                        
                except (IndexError, KeyError, ValueError, TypeError) as e:
                    print(f"ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆæ—¥ä»˜: {date}ï¼‰: {e}")
                    continue
        
        return signals_df
    
    def forecast_adjustment(self, signals_df, forecast_df, weight=0.5):
        """ã‚·ã‚°ãƒŠãƒ«ã«åŸºã¥ã„ã¦äºˆæ¸¬ä¾¡æ ¼ã‚’è£œæ­£"""
        if forecast_df is None or forecast_df.empty:
            return pd.DataFrame()
        
        adjusted_forecast = forecast_df.copy()
        
        if 'predicted_price' in adjusted_forecast.columns:
            adjusted_forecast['predicted_price'] = adjusted_forecast['predicted_price'].astype(np.float64)
        
        signal_dates = signals_df[signals_df['signal'] != 0]
        
        if not signal_dates.empty:
            for idx, row in signal_dates.iterrows():
                try:
                    date = row['Date']
                    signal = int(row['signal'])
                    score = float(row['anomaly_score'])
                    
                    future_mask = adjusted_forecast['Date'] >= date
                    future_idx = adjusted_forecast[future_mask].index.tolist()
                    
                    if len(future_idx) > 0:
                        for i, future_i in enumerate(future_idx):
                            decay = np.exp(-0.1 * i)
                            adjustment = signal * score * weight * decay
                            
                            current_pred = float(adjusted_forecast.loc[future_i, 'predicted_price'])
                            new_pred = current_pred * (1 + adjustment/100)
                            adjusted_forecast.loc[future_i, 'predicted_price'] = np.float64(new_pred)
                            
                except (ValueError, TypeError, KeyError) as e:
                    print(f"äºˆæ¸¬è£œæ­£ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        return adjusted_forecast

# ã‚«ã‚¹ã‚¿ãƒ CSS
CUSTOM_CSS = """
<style>
/* ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒŠã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
.main-container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 20px;
}

/* ãƒ˜ãƒƒãƒ€ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ« */
.header {
    text-align: center;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 30px;
    border-radius: 15px;
    margin-bottom: 30px;
    box-shadow: 0 8px 32px rgba(0,0,0,0.1);
}

.header h1 {
    font-size: 2.5rem;
    margin-bottom: 10px;
    font-weight: 700;
}

.header p {
    font-size: 1.2rem;
    opacity: 0.9;
    margin: 0;
}

/* ã‚«ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ« */
.config-card, .results-card {
    background: white;
    border-radius: 15px;
    padding: 25px;
    margin-bottom: 25px;
    box-shadow: 0 4px 20px rgba(0,0,0,0.08);
    border: 1px solid #e1e8ed;
}

.config-card h3, .results-card h3 {
    color: #2c3e50;
    border-bottom: 2px solid #3498db;
    padding-bottom: 10px;
    margin-bottom: 20px;
    font-weight: 600;
}

/* ãƒœã‚¿ãƒ³ã‚³ãƒ³ãƒ†ãƒŠ */
.button-container {
    display: flex;
    justify-content: center;
    align-items: center;
    padding: 30px 0;
    margin: 20px 0;
}

/* ãƒœã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ« */
.primary-btn {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    color: white;
    padding: 18px 40px;
    border-radius: 12px;
    font-size: 1.2rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s ease;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    min-width: 280px;
    text-align: center;
    display: inline-block;
}

.primary-btn:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    background: linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%);
}

.primary-btn:active {
    transform: translateY(0px);
    box-shadow: 0 2px 10px rgba(102, 126, 234, 0.3);
}

.secondary-btn {
    background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);
    border: none;
    color: white;
    padding: 12px 24px;
    border-radius: 8px;
    font-size: 1rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
    width: 100%;
    margin: 10px 0;
}

.secondary-btn:hover {
    transform: translateY(-1px);
    box-shadow: 0 4px 15px rgba(76, 175, 80, 0.3);
}

/* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º */
.status-success {
    background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);
    color: white;
    padding: 15px;
    border-radius: 10px;
    text-align: center;
    font-weight: 600;
    margin: 15px 0;
}

.status-error {
    background: linear-gradient(135deg, #f44336 0%, #d32f2f 100%);
    color: white;
    padding: 15px;
    border-radius: 10px;
    text-align: center;
    font-weight: 600;
    margin: 15px 0;
}

.status-warning {
    background: linear-gradient(135deg, #ff9800 0%, #f57c00 100%);
    color: white;
    padding: 15px;
    border-radius: 10px;
    text-align: center;
    font-weight: 600;
    margin: 15px 0;
}

/* ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ */
.progress-container {
    background: #f0f0f0;
    border-radius: 10px;
    padding: 20px;
    margin: 15px 0;
    text-align: center;
}

.progress-bar {
    width: 100%;
    height: 8px;
    background: #e0e0e0;
    border-radius: 4px;
    overflow: hidden;
    margin: 10px 0;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    border-radius: 4px;
    transition: width 0.3s ease;
}

/* çµæœã‚¿ãƒ– */
.tab-container {
    background: white;
    border-radius: 15px;
    overflow: hidden;
    box-shadow: 0 4px 20px rgba(0,0,0,0.08);
}

/* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ */
.metrics-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 20px;
    margin: 20px 0;
}

.metric-card {
    background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
    padding: 20px;
    border-radius: 12px;
    text-align: center;
    border-left: 4px solid #667eea;
}

.metric-value {
    font-size: 2rem;
    font-weight: 700;
    color: #2c3e50;
    margin-bottom: 5px;
}

.metric-label {
    font-size: 0.9rem;
    color: #6c757d;
    font-weight: 500;
}

/* ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ */
@keyframes fadeIn {
    from { opacity: 0; transform: translateY(20px); }
    to { opacity: 1; transform: translateY(0); }
}

.fade-in {
    animation: fadeIn 0.6s ease-out;
}

/* ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ */
@media (max-width: 768px) {
    .header h1 { font-size: 2rem; }
    .header p { font-size: 1rem; }
    .config-card, .results-card { padding: 15px; }
    .metrics-grid { grid-template-columns: 1fr; }
}

/* ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‚¹ã‚¿ã‚¤ãƒ« */
.agent-result {
    background: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 12px;
    margin-bottom: 20px;
    overflow: hidden;
}

.agent-header {
    background: linear-gradient(135deg, #495057 0%, #343a40 100%);
    color: white;
    padding: 15px 20px;
    font-weight: 600;
    cursor: pointer;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.agent-content {
    padding: 20px;
    border-top: 1px solid #dee2e6;
}

.agent-content pre {
    background: white;
    padding: 15px;
    border-radius: 8px;
    border: 1px solid #e9ecef;
    white-space: pre-wrap;
    font-family: 'Courier New', monospace;
    font-size: 0.9rem;
    line-height: 1.5;
}

/* è©•ä¾¡çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚¿ã‚¤ãƒ« */
.evaluation-table {
    background: white;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    margin: 15px 0;
}

.evaluation-table table {
    width: 100%;
    border-collapse: collapse;
}

.evaluation-table th {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 12px;
    text-align: left;
    font-weight: 600;
}

.evaluation-table td {
    padding: 12px;
    border-bottom: 1px solid #e9ecef;
}

.evaluation-table tr:hover {
    background: #f8f9fa;
}
</style>
"""

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹çŠ¶æ…‹ã‚’ç®¡ç†
progress_state = {"current": 0, "total": 0, "message": ""}

def update_progress(current, total, message):
    """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹çŠ¶æ…‹ã‚’æ›´æ–°"""
    progress_state["current"] = current
    progress_state["total"] = total
    progress_state["message"] = message

def get_progress_html():
    """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®HTMLã‚’ç”Ÿæˆ"""
    if progress_state["total"] == 0:
        return ""
    
    percentage = (progress_state["current"] / progress_state["total"]) * 100
    return f"""
    <div class="progress-container fade-in">
        <h4>åˆ†æé€²è¡ŒçŠ¶æ³</h4>
        <div class="progress-bar">
            <div class="progress-fill" style="width: {percentage}%"></div>
        </div>
        <p>{progress_state['message']} ({progress_state['current']}/{progress_state['total']})</p>
        <p>{percentage:.1f}% å®Œäº†</p>
    </div>
    """

# ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
def prepare_data(use_sample, file_path=None, symbol='sp500', include_extra_indicators=True, period="2y"):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
    try:
        if use_sample:
            if data_manager and REALTIME_AVAILABLE:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                if include_extra_indicators:
                    # è¤‡æ•°æŒ‡æ¨™ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    data_dict = data_manager.load_multi_indicator_data()
                    
                    # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆæŒ‡å®šã•ã‚ŒãŸã‚·ãƒ³ãƒœãƒ«ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯S&P500ï¼‰
                    main_symbol = symbol if symbol in data_dict else 'sp500'
                    df = data_dict[main_symbol].copy()
                    
                    # è¿½åŠ æŒ‡æ¨™ã‚’ãƒãƒ¼ã‚¸
                    if 'volume' in data_dict and not data_dict['volume'].empty:
                        df = pd.merge(df, data_dict['volume'][['Date', 'Volume']], on='Date', how='left')
                    
                    if 'vix' in data_dict and not data_dict['vix'].empty:
                        df = pd.merge(df, data_dict['vix'][['Date', 'VIX']], on='Date', how='left')
                    
                    if 'usdjpy' in data_dict and not data_dict['usdjpy'].empty:
                        df = pd.merge(df, data_dict['usdjpy'][['Date', 'USDJPY']], on='Date', how='left')
                else:
                    # å˜ä¸€ã‚·ãƒ³ãƒœãƒ«ã®ãƒ‡ãƒ¼ã‚¿
                    df = data_manager.load_sample_data(symbol=symbol)
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—¢å­˜ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
                from utils.data_utils import load_sample_data, load_multi_indicator_data
                if include_extra_indicators:
                    data_dict = load_multi_indicator_data(START_DATE, END_DATE)
                    df = data_dict['sp500']
                    
                    if 'volume' in data_dict:
                        df = pd.merge(df, data_dict['volume'][['Date', 'Volume']], on='Date', how='left')
                    
                    if 'vix' in data_dict:
                        df = pd.merge(df, data_dict['vix'][['Date', 'VIX']], on='Date', how='left')
                    
                    if 'usdjpy' in data_dict:
                        df = pd.merge(df, data_dict['usdjpy'][['Date', 'USDJPY']], on='Date', how='left')
                else:
                    df = load_sample_data(START_DATE, END_DATE)
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å ´åˆï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾ç¶­æŒï¼‰
            if file_path is None or file_path == "":
                raise ValueError("ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path)
            elif file_path.endswith(('.xls', '.xlsx')):
                df = pd.read_excel(file_path)
            else:
                raise ValueError("å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚CSVã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'])
            else:
                df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])
                df.rename(columns={df.columns[0]: 'Date'}, inplace=True)
            
            if 'Close' not in df.columns:
                df.rename(columns={df.columns[1]: 'Close'}, inplace=True)
        
        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã¨å‰å‡¦ç†
        if df.empty:
            raise ValueError("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
        df = df.sort_values('Date').reset_index(drop=True)
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèªã¨ä¿®æ­£
        df['Close'] = pd.to_numeric(df['Close'], errors='coerce')
        df = df.dropna(subset=['Close'])
        
        if df.empty:
            raise ValueError("æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
        if not df.empty:
            print(f"ğŸ“… æœŸé–“: {df['Date'].min().date()} - {df['Date'].max().date()}")
        
        return df
        
    except Exception as e:
        print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
        # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if data_manager:
            return data_manager._generate_fallback_data()
        else:
            # ç·Šæ€¥æ™‚ã®æœ€å°é™ãƒ‡ãƒ¼ã‚¿
            dates = pd.date_range(start='2022-01-01', end='2024-01-01', freq='D')
            prices = np.random.normal(4000, 200, len(dates))
            return pd.DataFrame({'Date': dates, 'Close': prices})

# ä¿®æ­£ç‰ˆDeep SVDDæ¤œå‡ºå™¨ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
class FixedDeepSVDDDetector:
    """Deep SVDD ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    
    def __init__(self, threshold=0.9, epochs=20, batch_size=32, random_state=42):
        self.threshold = threshold
        self.epochs = epochs
        self.batch_size = batch_size
        self.random_state = random_state
        self.model = None
        
    def detect(self, data, date_column='Date', value_column='Close', extra_features=None):
        """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å†…ã®ç•°å¸¸ã‚’æ¤œå‡º"""
        try:
            import tensorflow as tf
            from sklearn.preprocessing import StandardScaler
            
            df = data.copy()
            
            # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨æ¤œè¨¼
            if df.empty or len(df) < 20:
                print(f"è­¦å‘Š: Deep SVDDç”¨ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df)}ä»¶ï¼‰")
                return pd.DataFrame()
            
            # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’ä½œæˆ
            df['returns'] = df[value_column].pct_change().fillna(0)
            df['log_returns'] = np.log1p(df['returns'])
            
            # ç§»å‹•å¹³å‡é–¢é€£ã®ç‰¹å¾´é‡ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼‰
            window_size = min(5, len(df) // 4)
            df['rolling_mean'] = df[value_column].rolling(window=window_size, min_periods=1).mean()
            df['rolling_std'] = df[value_column].rolling(window=window_size, min_periods=1).std()
            df['rolling_z'] = (df[value_column] - df['rolling_mean']) / (df['rolling_std'] + 1e-8)
            
            # ã‚ˆã‚Šå°ã•ãªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ç§»å‹•å¹³å‡
            ma_window = min(10, len(df) // 2)
            df['ma'] = df[value_column].rolling(window=ma_window, min_periods=1).mean()
            df['ma_ratio'] = df[value_column] / (df['ma'] + 1e-8)
            
            # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            features = ['returns', 'log_returns', 'rolling_z', 'ma_ratio']
            
            # è¿½åŠ ã®ç‰¹å¾´é‡ãŒã‚ã‚Œã°è¿½åŠ 
            if extra_features:
                for feature in extra_features:
                    if feature in df.columns:
                        features.append(feature)
            
            # NaNå€¤ã‚’å‡¦ç†
            df_features = df.dropna()
            
            if df_features.empty or len(df_features) < 10:
                print(f"è­¦å‘Š: Deep SVDDç‰¹å¾´é‡å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df_features)}ä»¶ï¼‰")
                return pd.DataFrame()
            
            # ç‰¹å¾´é‡ã‚’æŠ½å‡º
            X = df_features[features].values
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            if X.shape[0] == 0 or X.shape[1] == 0:
                print("è­¦å‘Š: Deep SVDDç‰¹å¾´é‡é…åˆ—ãŒç©ºã§ã™")
                return pd.DataFrame()
            
            # ç„¡é™å€¤ã‚„NaNå€¤ã‚’ãƒã‚§ãƒƒã‚¯
            if not np.isfinite(X).all():
                X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)
            
            # ç‰¹å¾´é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # ç°¡å˜ãªã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆï¼ˆDeep SVDDã®ç°¡æ˜“ç‰ˆï¼‰
            input_dim = X_scaled.shape[1]
            
            # TensorFlowã®ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š
            tf.random.set_seed(self.random_state)
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
            encoder = tf.keras.Sequential([
                tf.keras.layers.Dense(max(2, input_dim // 2), activation='relu', input_shape=(input_dim,)),
                tf.keras.layers.Dense(2, activation='linear')  # 2æ¬¡å…ƒã®æ½œåœ¨ç©ºé–“
            ])
            
            decoder = tf.keras.Sequential([
                tf.keras.layers.Dense(max(2, input_dim // 2), activation='relu', input_shape=(2,)),
                tf.keras.layers.Dense(input_dim, activation='linear')
            ])
            
            # ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’çµåˆ
            autoencoder = tf.keras.Sequential([encoder, decoder])
            autoencoder.compile(optimizer='adam', loss='mse')
            
            # å­¦ç¿’ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼‰
            batch_size = min(self.batch_size, len(X_scaled) // 2)
            if batch_size < 1:
                batch_size = 1
                
            history = autoencoder.fit(
                X_scaled, X_scaled,
                epochs=self.epochs,
                batch_size=batch_size,
                verbose=0,
                validation_split=0.1 if len(X_scaled) > 10 else 0
            )
            
            # å†æ§‹æˆã‚¨ãƒ©ãƒ¼ã‚’è¨ˆç®—
            X_pred = autoencoder.predict(X_scaled, verbose=0)
            reconstruction_errors = np.mean(np.square(X_scaled - X_pred), axis=1)
            
            # ç•°å¸¸åˆ¤å®šã®ãŸã‚ã®é–¾å€¤ã‚’è¨ˆç®—
            error_threshold = np.percentile(reconstruction_errors, self.threshold * 100)
            
            # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
            df_features['anomaly_score'] = reconstruction_errors
            df_features['is_anomaly'] = reconstruction_errors > error_threshold
            
            # å¤‰åŒ–ç‡ã‚’è¿½åŠ 
            df_features['pct_change'] = df_features[value_column].pct_change() * 100
            
            # ç•°å¸¸ã®ã¿ã‚’æŠ½å‡º
            anomalies = df_features[df_features['is_anomaly']].copy()
            
            return anomalies
            
        except Exception as e:
            print(f"Deep SVDDæ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return pd.DataFrame()

# ä¿®æ­£ç‰ˆIsolation Forestæ¤œå‡ºå™¨ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œå¼·åŒ–ï¼‰
class FixedIsolationForestDetector:
    """Isolation Forest ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œå¼·åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, contamination=0.05, n_estimators=100, random_state=42):
        self.contamination = contamination
        self.n_estimators = n_estimators
        self.random_state = random_state
        self.model = None
        
    def detect(self, data, date_column='Date', value_column='Close', extra_features=None):
        """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å†…ã®ç•°å¸¸ã‚’æ¤œå‡º"""
        try:
            from sklearn.ensemble import IsolationForest
            from sklearn.preprocessing import StandardScaler
            
            df = data.copy()
            
            # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨æ¤œè¨¼ï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
            if df.empty or len(df) < 10:
                print(f"è­¦å‘Š: Isolation Forestç”¨ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df)}ä»¶ï¼‰")
                return pd.DataFrame()
            
            # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’ä½œæˆ
            df['returns'] = df[value_column].pct_change().fillna(0)
            df['log_returns'] = np.log1p(df['returns'])
            
            # ç§»å‹•å¹³å‡é–¢é€£ã®ç‰¹å¾´é‡ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’å‹•çš„èª¿æ•´ï¼‰
            window_5 = min(5, max(2, len(df) // 10))
            window_20 = min(20, max(5, len(df) // 5))
            window_50 = min(50, max(10, len(df) // 2))
            
            df['rolling_mean_5'] = df[value_column].rolling(window=window_5, min_periods=1).mean()
            df['rolling_std_5'] = df[value_column].rolling(window=window_5, min_periods=1).std()
            df['rolling_z'] = (df[value_column] - df['rolling_mean_5']) / (df['rolling_std_5'] + 1e-8)
            
            df['ma_20'] = df[value_column].rolling(window=window_20, min_periods=1).mean()
            df['ma_50'] = df[value_column].rolling(window=window_50, min_periods=1).mean()
            df['ma_ratio_20'] = df[value_column] / (df['ma_20'] + 1e-8)
            df['ma_ratio_50'] = df[value_column] / (df['ma_50'] + 1e-8)
            
            # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            features = [
                'returns', 'log_returns', 'rolling_z',
                'ma_ratio_20', 'ma_ratio_50'
            ]
            
            # è¿½åŠ ã®ç‰¹å¾´é‡ãŒã‚ã‚Œã°è¿½åŠ 
            if extra_features:
                for feature in extra_features:
                    if feature in df.columns:
                        features.append(feature)
            
            # NaNå€¤ã‚’å‡¦ç†
            df_features = df.dropna()
            
            if df_features.empty or len(df_features) < 5:
                print(f"è­¦å‘Š: Isolation Forestç‰¹å¾´é‡å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df_features)}ä»¶ï¼‰")
                return pd.DataFrame()
            
            # ç‰¹å¾´é‡ã‚’æŠ½å‡º
            X = df_features[features].values
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            if X.shape[0] == 0 or X.shape[1] == 0:
                print("è­¦å‘Š: Isolation Forestç‰¹å¾´é‡é…åˆ—ãŒç©ºã§ã™")
                return pd.DataFrame()
            
            # ç„¡é™å€¤ã‚„NaNå€¤ã‚’ãƒã‚§ãƒƒã‚¯
            if not np.isfinite(X).all():
                print("è­¦å‘Š: Isolation Forestç‰¹å¾´é‡ã«ç„¡é™å€¤ã¾ãŸã¯NaNå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)
            
            # ç‰¹å¾´é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # contaminationå€¤ã‚’èª¿æ•´ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«å¿œã˜ã¦ï¼‰
            effective_contamination = min(self.contamination, 0.5)  # æœ€å¤§50%
            if len(X_scaled) < 20:
                effective_contamination = min(0.1, 1.0 / len(X_scaled))  # å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ä½ã„å€¤
            
            # Isolation Forestãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»é©ç”¨
            self.model = IsolationForest(
                contamination=effective_contamination,
                n_estimators=min(self.n_estimators, 50),  # è¨ˆç®—é‡ã‚’å‰Šæ¸›
                random_state=self.random_state,
                n_jobs=1  # ä¸¦åˆ—å‡¦ç†ã‚’ç„¡åŠ¹åŒ–ï¼ˆå®‰å®šæ€§å‘ä¸Šï¼‰
            )
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆ
            self.model.fit(X_scaled)
            
            # ç•°å¸¸ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬
            anomaly_scores = self.model.score_samples(X_scaled)
            anomaly_labels = self.model.predict(X_scaled)
            
            # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
            df_features['anomaly_score'] = anomaly_scores
            df_features['is_anomaly'] = anomaly_labels == -1  # -1ãŒç•°å¸¸ã€1ãŒæ­£å¸¸
            
            # å¤‰åŒ–ç‡ã‚’è¿½åŠ 
            df_features['pct_change'] = df_features[value_column].pct_change() * 100
            
            # ç•°å¸¸ã®ã¿ã‚’æŠ½å‡º
            anomalies = df_features[df_features['is_anomaly']].copy()
            
            print(f"Isolation Forestå®Œäº†: å…¥åŠ› {len(df_features)}ä»¶, ç•°å¸¸ {len(anomalies)}ä»¶")
            return anomalies
            
        except Exception as e:
            print(f"Isolation Forestæ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    """Isolation Forest ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    
    def __init__(self, contamination=0.05, n_estimators=100, random_state=42):
        self.contamination = contamination
        self.n_estimators = n_estimators
        self.random_state = random_state
        self.model = None
        
    def detect(self, data, date_column='Date', value_column='Close', extra_features=None):
        """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å†…ã®ç•°å¸¸ã‚’æ¤œå‡º"""
        from sklearn.ensemble import IsolationForest
        from sklearn.preprocessing import StandardScaler
        
        df = data.copy()
        
        # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨æ¤œè¨¼ï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
        if df.empty or len(df) < 5:  # 10 â†’ 5ã«å¤‰æ›´
            print(f"è­¦å‘Š: Isolation Forestç”¨ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df)}ä»¶ï¼‰")
            return pd.DataFrame()
        
        # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’ä½œæˆ
        try:
            df['returns'] = df[value_column].pct_change()
            df['log_returns'] = np.log1p(df['returns'].fillna(0))
            
            # ç§»å‹•å¹³å‡é–¢é€£ã®ç‰¹å¾´é‡
            df['rolling_mean_5'] = df[value_column].rolling(window=5, min_periods=1).mean()
            df['rolling_std_5'] = df[value_column].rolling(window=5, min_periods=1).std()
            df['rolling_z'] = (df[value_column] - df['rolling_mean_5']) / (df['rolling_std_5'] + 1e-8)
            
            df['ma_20'] = df[value_column].rolling(window=20, min_periods=1).mean()
            df['ma_50'] = df[value_column].rolling(window=50, min_periods=1).mean()
            df['ma_ratio_20'] = df[value_column] / (df['ma_20'] + 1e-8)
            df['ma_ratio_50'] = df[value_column] / (df['ma_50'] + 1e-8)
            
            # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            features = [
                'returns', 'log_returns', 'rolling_z',
                'ma_ratio_20', 'ma_ratio_50'
            ]
            
            # è¿½åŠ ã®ç‰¹å¾´é‡ãŒã‚ã‚Œã°è¿½åŠ 
            if extra_features:
                for feature in extra_features:
                    if feature in df.columns:
                        features.append(feature)
            
            # NaNå€¤ã‚’å‡¦ç†
            df_features = df.dropna()
            
            if df_features.empty or len(df_features) < 3:  # 5 â†’ 3ã«å¤‰æ›´
                print(f"è­¦å‘Š: Isolation Forestç‰¹å¾´é‡å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df_features)}ä»¶ï¼‰")
                return pd.DataFrame()
            
            # ç‰¹å¾´é‡ã‚’æŠ½å‡º
            X = df_features[features].values
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            if X.shape[0] == 0 or X.shape[1] == 0:
                print("è­¦å‘Š: ç‰¹å¾´é‡é…åˆ—ãŒç©ºã§ã™")
                return pd.DataFrame()
            
            # ç„¡é™å€¤ã‚„NaNå€¤ã‚’ãƒã‚§ãƒƒã‚¯
            if not np.isfinite(X).all():
                print("è­¦å‘Š: ç‰¹å¾´é‡ã«ç„¡é™å€¤ã¾ãŸã¯NaNå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)
            
            # ç‰¹å¾´é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # Isolation Forestãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»é©ç”¨
            self.model = IsolationForest(
                contamination=self.contamination,
                n_estimators=self.n_estimators,
                random_state=self.random_state
            )
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆ
            self.model.fit(X_scaled)
            
            # ç•°å¸¸ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬
            anomaly_scores = self.model.score_samples(X_scaled)
            anomaly_labels = self.model.predict(X_scaled)
            
            # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
            df_features['anomaly_score'] = anomaly_scores
            df_features['is_anomaly'] = anomaly_labels == -1  # -1ãŒç•°å¸¸ã€1ãŒæ­£å¸¸
            
            # å¤‰åŒ–ç‡ã‚’è¿½åŠ 
            df_features['pct_change'] = df_features[value_column].pct_change() * 100
            
            # ç•°å¸¸ã®ã¿ã‚’æŠ½å‡º
            anomalies = df_features[df_features['is_anomaly']].copy()
            
            return anomalies
            
        except Exception as e:
            print(f"Isolation Forestæ¤œå‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return pd.DataFrame()

# ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œï¼ˆå …ç‰¢ç‰ˆï¼‰
def detect_anomalies(df, method, threshold, extra_indicators=None):
    """ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œï¼ˆå …ç‰¢ç‰ˆï¼‰"""
    try:
        method_params = ANOMALY_PARAMS.get(method, {})
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿å‹ã‚’çµ±ä¸€
        df_copy = df.copy()
        
        # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
        if df_copy.empty or len(df_copy) < 5:  # 10 â†’ 5ã«å¤‰æ›´
            print(f"è­¦å‘Š: ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df_copy)}ä»¶ï¼‰")
            return pd.DataFrame()
        
        # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’float64ã«çµ±ä¸€
        numeric_columns = ['Close']
        for col in numeric_columns:
            if col in df_copy.columns:
                df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')
                df_copy[col] = df_copy[col].astype(np.float64)
        
        # NaNå€¤ã‚’é™¤å»
        original_length = len(df_copy)
        df_copy = df_copy.dropna(subset=['Close'])
        final_length = len(df_copy)
        
        if df_copy.empty or len(df_copy) < 3:  # 5 â†’ 3ã«å¤‰æ›´
            print(f"è­¦å‘Š: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{final_length}ä»¶ã€å…ƒ: {original_length}ä»¶ï¼‰")
            return pd.DataFrame()
        
        print(f"ç•°å¸¸æ¤œçŸ¥å®Ÿè¡Œ: æ‰‹æ³• {method}, ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_copy)}ä»¶")
        
        extra_features = None
        if extra_indicators:
            extra_features = []
            if 'Volume' in df_copy.columns:
                df_copy['Volume'] = pd.to_numeric(df_copy['Volume'], errors='coerce').fillna(0)
                df_copy['Volume'] = df_copy['Volume'].astype(np.float64)
                volume_ma = df_copy['Volume'].rolling(window=20, min_periods=1).mean()
                df_copy['volume_ratio'] = df_copy['Volume'] / (volume_ma + 1e-8)
                df_copy['volume_ratio'] = df_copy['volume_ratio'].astype(np.float64)
                extra_features.append('volume_ratio')
            
            if 'VIX' in df_copy.columns:
                df_copy['VIX'] = pd.to_numeric(df_copy['VIX'], errors='coerce').fillna(20.0)
                df_copy['VIX'] = df_copy['VIX'].astype(np.float64)
                extra_features.append('VIX')
            
            if 'USDJPY' in df_copy.columns:
                df_copy['USDJPY'] = pd.to_numeric(df_copy['USDJPY'], errors='coerce').fillna(110.0)
                df_copy['USDJPY'] = df_copy['USDJPY'].astype(np.float64)
                df_copy['usdjpy_pct_change'] = df_copy['USDJPY'].pct_change() * 100
                df_copy['usdjpy_pct_change'] = df_copy['usdjpy_pct_change'].astype(np.float64)
                extra_features.append('usdjpy_pct_change')
        
        # æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã®å ´åˆã¯ä¿®æ­£ç‰ˆæ¤œå‡ºå™¨ã‚’ä½¿ç”¨
        if method == 'isolation_forest':
            detector = FixedIsolationForestDetector(
                contamination=method_params.get('contamination', 0.05),
                n_estimators=method_params.get('n_estimators', 100),
                random_state=method_params.get('random_state', 42)
            )
            return detector.detect(df_copy, extra_features=extra_features)
        elif method == 'deep_svdd':
            detector = FixedDeepSVDDDetector(
                threshold=method_params.get('threshold', 0.95),
                epochs=method_params.get('epochs', 20),  # ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å‰Šæ¸›
                batch_size=method_params.get('batch_size', 32),
                random_state=method_params.get('random_state', 42)
            )
            return detector.detect(df_copy, extra_features=extra_features)
        else:
            # å¾“æ¥ã®æ¤œå‡ºå™¨ã‚’ä½¿ç”¨
            detector = AnomalyDetector(method=method, threshold=float(threshold), **method_params)
            return detector.detect(df_copy, extra_features=extra_features)
        
    except Exception as e:
        print(f"ç•°å¸¸æ¤œçŸ¥ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()
    """ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œï¼ˆå …ç‰¢ç‰ˆï¼‰"""
    try:
        method_params = ANOMALY_PARAMS.get(method, {})
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿å‹ã‚’çµ±ä¸€
        df_copy = df.copy()
        
        # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        if df_copy.empty or len(df_copy) < 10:
            print("è­¦å‘Š: ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return pd.DataFrame()
        
        # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’float64ã«çµ±ä¸€
        numeric_columns = ['Close']
        for col in numeric_columns:
            if col in df_copy.columns:
                df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')
                df_copy[col] = df_copy[col].astype(np.float64)
        
        # NaNå€¤ã‚’é™¤å»
        df_copy = df_copy.dropna(subset=['Close'])
        
        if df_copy.empty or len(df_copy) < 5:
            print("è­¦å‘Š: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return pd.DataFrame()
        
        extra_features = None
        if extra_indicators:
            extra_features = []
            if 'Volume' in df_copy.columns:
                df_copy['Volume'] = pd.to_numeric(df_copy['Volume'], errors='coerce').fillna(0)
                df_copy['Volume'] = df_copy['Volume'].astype(np.float64)
                volume_ma = df_copy['Volume'].rolling(window=20, min_periods=1).mean()
                df_copy['volume_ratio'] = df_copy['Volume'] / (volume_ma + 1e-8)
                df_copy['volume_ratio'] = df_copy['volume_ratio'].astype(np.float64)
                extra_features.append('volume_ratio')
            
            if 'VIX' in df_copy.columns:
                df_copy['VIX'] = pd.to_numeric(df_copy['VIX'], errors='coerce').fillna(20.0)
                df_copy['VIX'] = df_copy['VIX'].astype(np.float64)
                extra_features.append('VIX')
            
            if 'USDJPY' in df_copy.columns:
                df_copy['USDJPY'] = pd.to_numeric(df_copy['USDJPY'], errors='coerce').fillna(110.0)
                df_copy['USDJPY'] = df_copy['USDJPY'].astype(np.float64)
                df_copy['usdjpy_pct_change'] = df_copy['USDJPY'].pct_change() * 100
                df_copy['usdjpy_pct_change'] = df_copy['usdjpy_pct_change'].astype(np.float64)
                extra_features.append('usdjpy_pct_change')
        
        # æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã®å ´åˆã¯ä¿®æ­£ç‰ˆæ¤œå‡ºå™¨ã‚’ä½¿ç”¨
        if method == 'isolation_forest':
            detector = FixedIsolationForestDetector(
                contamination=method_params.get('contamination', 0.05),
                n_estimators=method_params.get('n_estimators', 100),
                random_state=method_params.get('random_state', 42)
            )
            return detector.detect(df_copy, extra_features=extra_features)
        else:
            # å¾“æ¥ã®æ¤œå‡ºå™¨ã‚’ä½¿ç”¨
            detector = AnomalyDetector(method=method, threshold=float(threshold), **method_params)
            return detector.detect(df_copy, extra_features=extra_features)
        
    except Exception as e:
        print(f"ç•°å¸¸æ¤œçŸ¥ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()
    """ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ¼ã‚¿å‹å•é¡Œä¿®æ­£ç‰ˆï¼‰"""
    method_params = ANOMALY_PARAMS.get(method, {})
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿å‹ã‚’çµ±ä¸€
    df_copy = df.copy()
    
    # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’float64ã«çµ±ä¸€
    numeric_columns = ['Close']
    for col in numeric_columns:
        if col in df_copy.columns:
            df_copy[col] = df_copy[col].astype(np.float64)
    
    extra_features = None
    if extra_indicators:
        extra_features = []
        if 'Volume' in df_copy.columns:
            df_copy['Volume'] = df_copy['Volume'].astype(np.float64)
            df_copy['volume_ratio'] = df_copy['Volume'] / df_copy['Volume'].rolling(window=20).mean()
            df_copy['volume_ratio'] = df_copy['volume_ratio'].astype(np.float64)
            extra_features.append('volume_ratio')
        
        if 'VIX' in df_copy.columns:
            df_copy['VIX'] = df_copy['VIX'].astype(np.float64)
            extra_features.append('VIX')
        
        if 'USDJPY' in df_copy.columns:
            df_copy['USDJPY'] = df_copy['USDJPY'].astype(np.float64)
            df_copy['usdjpy_pct_change'] = df_copy['USDJPY'].pct_change() * 100
            df_copy['usdjpy_pct_change'] = df_copy['usdjpy_pct_change'].astype(np.float64)
            extra_features.append('usdjpy_pct_change')
    
    try:
        detector = AnomalyDetector(method=method, threshold=float(threshold), **method_params)
        anomalies = detector.detect(df_copy, extra_features=extra_features)
        
        # ç•°å¸¸æ¤œçŸ¥çµæœã®ãƒ‡ãƒ¼ã‚¿å‹ã‚‚çµ±ä¸€
        if not anomalies.empty:
            for col in ['Close', 'pct_change']:
                if col in anomalies.columns:
                    anomalies[col] = anomalies[col].astype(np.float64)
        
        return anomalies
    except Exception as e:
        print(f"ç•°å¸¸æ¤œçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
        return pd.DataFrame()

# æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
def create_enhanced_plot(df, anomalies):
    """æ”¹å–„ã•ã‚ŒãŸæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨ç•°å¸¸å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿å‹å•é¡Œå¯¾å¿œï¼‰"""
    try:
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã¨æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸', 'æ—¥æ¬¡å¤‰åŒ–ç‡'),
            vertical_spacing=0.12,
            row_heights=[0.7, 0.3]
        )
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®å®‰å…¨ãªå¤‰æ›
        df_safe = df.copy()
        if 'Close' in df_safe.columns:
            df_safe['Close'] = pd.to_numeric(df_safe['Close'], errors='coerce')
        
        # ãƒ¡ã‚¤ãƒ³ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        fig.add_trace(
            go.Scatter(
                x=df_safe['Date'],
                y=df_safe['Close'],
                mode='lines',
                name='ä¾¡æ ¼',
                line=dict(color='#2E86AB', width=2),
                hovertemplate='<b>æ—¥ä»˜:</b> %{x}<br><b>ä¾¡æ ¼:</b> Â¥%{y:,.0f}<extra></extra>'
            ),
            row=1, col=1
        )
        
        # ç•°å¸¸å€¤
        if not anomalies.empty:
            anomalies_safe = anomalies.copy()
            if 'Close' in anomalies_safe.columns:
                anomalies_safe['Close'] = pd.to_numeric(anomalies_safe['Close'], errors='coerce')
            if 'pct_change' in anomalies_safe.columns:
                anomalies_safe['pct_change'] = pd.to_numeric(anomalies_safe['pct_change'], errors='coerce')
            else:
                anomalies_safe['pct_change'] = 0.0
                
            fig.add_trace(
                go.Scatter(
                    x=anomalies_safe['Date'],
                    y=anomalies_safe['Close'],
                    mode='markers',
                    name='æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸',
                    marker=dict(
                        color='#E63946',
                        size=12,
                        symbol='diamond',
                        line=dict(color='white', width=2)
                    ),
                    hovertemplate='<b>ç•°å¸¸æ—¥:</b> %{x}<br><b>ä¾¡æ ¼:</b> Â¥%{y:,.0f}<br><b>å¤‰åŒ–ç‡:</b> %{customdata:.2f}%<extra></extra>',
                    customdata=anomalies_safe['pct_change'].fillna(0)
                ),
                row=1, col=1
            )
        
        # å¤‰åŒ–ç‡ã®è¨ˆç®—ã¨è¡¨ç¤º
        if 'pct_change' not in df_safe.columns:
            df_safe['pct_change'] = df_safe['Close'].pct_change() * 100
        
        df_safe['pct_change'] = pd.to_numeric(df_safe['pct_change'], errors='coerce').fillna(0)
        
        # å¤‰åŒ–ç‡ãƒ—ãƒ­ãƒƒãƒˆ
        colors = ['#E63946' if abs(float(x)) > 2 else '#2E86AB' for x in df_safe['pct_change']]
        
        fig.add_trace(
            go.Bar(
                x=df_safe['Date'],
                y=df_safe['pct_change'],
                name='æ—¥æ¬¡å¤‰åŒ–ç‡',
                marker_color=colors,
                opacity=0.7,
                hovertemplate='<b>æ—¥ä»˜:</b> %{x}<br><b>å¤‰åŒ–ç‡:</b> %{y:.2f}%<extra></extra>'
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            title=dict(
                text='<b>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœ</b>',
                x=0.5,
                font=dict(size=20, color='#2c3e50')
            ),
            showlegend=True,
            height=700,
            template='plotly_white',
            hovermode='x unified',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        fig.update_xaxes(title_text="æ—¥ä»˜", row=2, col=1)
        fig.update_yaxes(title_text="ä¾¡æ ¼", row=1, col=1)
        fig.update_yaxes(title_text="å¤‰åŒ–ç‡ (%)", row=2, col=1)
        
        return fig
        
    except Exception as e:
        print(f"ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã®ãƒ—ãƒ­ãƒƒãƒˆã‚’è¿”ã™
        return go.Figure().add_annotation(text="ãƒ—ãƒ­ãƒƒãƒˆä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", 
                                        x=0.5, y=0.5, showarrow=False)

# äºˆæ¸¬ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
def create_enhanced_forecast_plot(df, anomalies, forecast_df, adjusted_forecast_df):
    """æ”¹å–„ã•ã‚ŒãŸäºˆæ¸¬ãƒ—ãƒ­ãƒƒãƒˆ"""
    fig = go.Figure()
    
    # å®Ÿéš›ã®ä¾¡æ ¼ï¼ˆæœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿è¡¨ç¤ºï¼‰
    recent_data = df.tail(100)
    fig.add_trace(go.Scatter(
        x=recent_data['Date'],
        y=recent_data['Close'],
        mode='lines',
        name='å®Ÿéš›ã®ä¾¡æ ¼',
        line=dict(color='#2E86AB', width=3),
        hovertemplate='<b>æ—¥ä»˜:</b> %{x}<br><b>å®Ÿéš›ä¾¡æ ¼:</b> Â¥%{y:,.0f}<extra></extra>'
    ))
    
    # ç•°å¸¸å€¤
    if not anomalies.empty:
        recent_anomalies = anomalies[anomalies['Date'] >= recent_data['Date'].min()]
        if not recent_anomalies.empty:
            fig.add_trace(go.Scatter(
                x=recent_anomalies['Date'],
                y=recent_anomalies['Close'],
                mode='markers',
                name='æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸',
                marker=dict(
                    color='#E63946',
                    size=12,
                    symbol='diamond',
                    line=dict(color='white', width=2)
                )
            ))
    
    # åŸºæœ¬äºˆæ¸¬
    if forecast_df is not None:
        fig.add_trace(go.Scatter(
            x=forecast_df['Date'],
            y=forecast_df['predicted_price'],
            mode='lines',
            name='åŸºæœ¬äºˆæ¸¬',
            line=dict(color='#F77F00', width=2, dash='dash'),
            hovertemplate='<b>äºˆæ¸¬æ—¥:</b> %{x}<br><b>åŸºæœ¬äºˆæ¸¬:</b> Â¥%{y:,.0f}<extra></extra>'
        ))
    
    # ç•°å¸¸èª¿æ•´æ¸ˆã¿äºˆæ¸¬
    if adjusted_forecast_df is not None:
        fig.add_trace(go.Scatter(
            x=adjusted_forecast_df['Date'],
            y=adjusted_forecast_df['predicted_price'],
            mode='lines',
            name='ç•°å¸¸èª¿æ•´æ¸ˆã¿äºˆæ¸¬',
            line=dict(color='#6A994E', width=3),
            hovertemplate='<b>äºˆæ¸¬æ—¥:</b> %{x}<br><b>èª¿æ•´æ¸ˆã¿äºˆæ¸¬:</b> Â¥%{y:,.0f}<extra></extra>'
        ))
    
    fig.update_layout(
        title=dict(
            text='<b>ä¾¡æ ¼äºˆæ¸¬åˆ†æ</b>',
            x=0.5,
            font=dict(size=20, color='#2c3e50')
        ),
        xaxis_title="æ—¥ä»˜",
        yaxis_title="ä¾¡æ ¼",
        template='plotly_white',
        height=600,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    return fig

# LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
def get_llm_client(provider):
    """æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ã«åŸºã¥ã„ã¦LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    if provider == "openai":
        return OpenAIClient(api_key=OPENAI_API_KEY, model=OPENAI_MODEL)
    elif provider == "huggingface":
        return HuggingFaceClient(api_key=HF_API_KEY, model=HF_MODEL)
    else:
        return MockLLMClient()

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œ
def run_agent_system(anomalies, llm_provider, enabled_agents, reference_data=None):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’è¿”ã™"""
    llm_client = get_llm_client(llm_provider)
    
    # é‡è¦ãªç•°å¸¸ã®ã¿ã«çµã‚‹
    if len(anomalies) > 3:
        anomalies = anomalies.iloc[anomalies['pct_change'].abs().argsort()[::-1][:3]].copy()
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    agents = []
    agent_names = []
    
    if 'web' in enabled_agents:
        agents.append(WebInformationAgent(llm_client=llm_client))
        agent_names.append('Webæƒ…å ±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ')
    
    if 'knowledge' in enabled_agents:
        agents.append(KnowledgeBaseAgent(llm_client=llm_client))
        agent_names.append('çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ')
    
    if 'crosscheck' in enabled_agents:
        agents.append(CrossCheckAgent(llm_client=llm_client))
        agent_names.append('ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ')
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
    context = {
        'reference_data': reference_data if reference_data else {}
    }
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‚’ä¿å­˜
    agent_findings = {}
    
    # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ä»˜ãï¼‰
    total_agents = len(agents) + (2 if 'report' in enabled_agents or 'manager' in enabled_agents else 0)
    current_agent = 0
    
    for i, agent in enumerate(agents):
        if agent.name in ["ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "ç®¡ç†è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"]:
            continue
        
        current_agent += 1
        update_progress(current_agent, total_agents, f"{agent.name}ã‚’å®Ÿè¡Œä¸­...")
        time.sleep(0.5)  # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºã®ãŸã‚
        
        agent_result = agent.process(anomalies, context)
        agent_findings[agent.name] = agent_result
    
    # çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
    if 'report' in enabled_agents:
        current_agent += 1
        update_progress(current_agent, total_agents, "ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œä¸­...")
        time.sleep(0.5)
        
        report_agent = ReportIntegrationAgent(llm_client=llm_client)
        context['agent_findings'] = agent_findings
        report_agent_result = report_agent.process(anomalies, context)
        agent_findings[report_agent.name] = report_agent_result
    
    # ç®¡ç†è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
    if 'manager' in enabled_agents:
        current_agent += 1
        update_progress(current_agent, total_agents, "ç®¡ç†è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œä¸­...")
        time.sleep(0.5)
        
        manager_agent = ManagerAgent(llm_client=llm_client)
        manager_agent_result = manager_agent.process(anomalies, context)
        agent_findings[manager_agent.name] = manager_agent_result
    
    update_progress(total_agents, total_agents, "åˆ†æå®Œäº†!")
    return agent_findings

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ã®HTMLç”Ÿæˆ
def create_metrics_cards(anomalies_count, total_data_points, detection_rate):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ã®HTMLã‚’ç”Ÿæˆ"""
    return f"""
    <div class="metrics-grid fade-in">
        <div class="metric-card">
            <div class="metric-value">{anomalies_count}</div>
            <div class="metric-label">æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸æ•°</div>
        </div>
        <div class="metric-card">
            <div class="metric-value">{total_data_points:,}</div>
            <div class="metric-label">ç·ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°</div>
        </div>
        <div class="metric-card">
            <div class="metric-value">{detection_rate:.3f}%</div>
            <div class="metric-label">ç•°å¸¸æ¤œå‡ºç‡</div>
        </div>
    </div>
    """

# åˆ†æã‚’å®Ÿè¡Œ
def run_analysis(data_source, file_path, detection_method, threshold, llm_provider, 
                use_web_agent, use_knowledge_agent, use_crosscheck_agent, 
                use_report_agent, use_manager_agent, include_extra_indicators=True,
                generate_signals=True, forecast_days=30, progress=gr.Progress()):
    try:
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹åˆæœŸåŒ–
        update_progress(0, 8, "åˆ†æã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...")
        progress(0.0, desc="åˆ†æã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        update_progress(1, 8, "ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...")
        progress(0.125, desc="ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...")
        use_sample = (data_source == "sample")
        df = prepare_data(use_sample, file_path, include_extra_indicators)
        
        # ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œ
        update_progress(2, 8, "ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œä¸­...")
        progress(0.25, desc="ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œä¸­...")
        anomalies = detect_anomalies(df, detection_method, threshold, include_extra_indicators)
        
        # ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ
        update_progress(3, 8, "å¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
        progress(0.375, desc="å¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
        plot = create_enhanced_plot(df, anomalies)
        
        # åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±
        anomalies_count = len(anomalies)
        total_data_points = len(df)
        detection_rate = (anomalies_count / total_data_points) * 100 if total_data_points > 0 else 0
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆ
        metrics_html = create_metrics_cards(anomalies_count, total_data_points, detection_rate)
        
        # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã¨ã—ã¦æ•´å½¢
        if anomalies.empty:
            anomalies_df = pd.DataFrame(columns=['æ—¥ä»˜', 'å€¤', 'å¤‰åŒ–ç‡ (%)'])
        else:
            anomalies_df = anomalies.copy()
            anomalies_df = anomalies_df[['Date', 'Close', 'pct_change']]
            anomalies_df.columns = ['æ—¥ä»˜', 'å€¤', 'å¤‰åŒ–ç‡ (%)']
            anomalies_df['æ—¥ä»˜'] = anomalies_df['æ—¥ä»˜'].dt.strftime('%Y-%m-%d')
            anomalies_df['å¤‰åŒ–ç‡ (%)'] = anomalies_df['å¤‰åŒ–ç‡ (%)'].round(2)
        
        # æœ‰åŠ¹ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        enabled_agents = []
        if use_web_agent:
            enabled_agents.append('web')
        if use_knowledge_agent:
            enabled_agents.append('knowledge')
        if use_crosscheck_agent:
            enabled_agents.append('crosscheck')
        if use_report_agent:
            enabled_agents.append('report')
        if use_manager_agent:
            enabled_agents.append('manager')
        
        # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        reference_data = {}
        if include_extra_indicators:
            if 'Volume' in df.columns:
                volume_df = df[['Date', 'Volume']].copy()
                reference_data['volume'] = volume_df
            
            if 'VIX' in df.columns:
                vix_df = df[['Date', 'VIX']].copy()
                reference_data['vix'] = vix_df
            
            if 'USDJPY' in df.columns:
                usdjpy_df = df[['Date', 'USDJPY']].copy()
                reference_data['usdjpy'] = usdjpy_df
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æã‚’å®Ÿè¡Œ
        update_progress(4, 8, "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æã‚’å®Ÿè¡Œä¸­...")
        progress(0.5, desc="ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æã‚’å®Ÿè¡Œä¸­...")
        
        agent_findings = {}
        if enabled_agents and not anomalies.empty:
            agent_findings = run_agent_system(anomalies, llm_provider, enabled_agents, reference_data)
        
        # ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆã¨äºˆæ¸¬
        update_progress(6, 8, "äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œä¸­...")
        progress(0.75, desc="äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œä¸­...")
        
        signals_df = None
        forecast_df = None
        adjusted_forecast_df = None
        forecast_plot = None
        
        if generate_signals and not anomalies.empty:
            # ä¿®æ­£ç‰ˆSignalGeneratorã‚’ä½¿ç”¨
            signal_generator = FixedSignalGenerator(
                threshold=SIGNAL_THRESHOLD, 
                window_size=SIGNAL_WINDOW
            )
            
            signals_df = signal_generator.generate_signals(df, anomalies)
            
            # äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
            pipeline = ForecastingPipeline(
                forecasting_model=FORECASTING_MODEL,
                signal_threshold=SIGNAL_THRESHOLD,
                window_size=SIGNAL_WINDOW,
                lookback=FORECASTING_PARAMS[FORECASTING_MODEL].get('lookback', 60)
            )
            
            # äºˆæ¸¬ã®ã¿å®Ÿè¡Œï¼ˆã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆã¯æ—¢ã«å®Œäº†ï¼‰
            _, forecast_df, _ = pipeline.process(
                df, anomalies, 
                train_model=True, 
                days_ahead=forecast_days, 
                adjustment_weight=0.5
            )
            
            # äºˆæ¸¬è£œæ­£ã‚’æ‰‹å‹•å®Ÿè¡Œ
            adjusted_forecast_df = signal_generator.forecast_adjustment(
                signals_df, forecast_df, weight=0.5
            )
            
            forecast_plot = create_enhanced_forecast_plot(df, anomalies, forecast_df, adjusted_forecast_df)
        
        # ã‚·ã‚°ãƒŠãƒ«ã‚’è¡¨ã¨ã—ã¦æ•´å½¢
        signals_table = pd.DataFrame()
        if signals_df is not None and not signals_df.empty:
            signals_table = signals_df[signals_df['signal'] != 0][['Date', 'Close', 'pct_change', 'signal', 'anomaly_score']]
            if not signals_table.empty:
                signals_table.columns = ['æ—¥ä»˜', 'ä¾¡æ ¼', 'å¤‰åŒ–ç‡ (%)', 'ã‚·ã‚°ãƒŠãƒ«(-1=å£²/1=è²·)', 'ç•°å¸¸å¼·åº¦']
                signals_table['æ—¥ä»˜'] = signals_table['æ—¥ä»˜'].dt.strftime('%Y-%m-%d')
                signals_table['å¤‰åŒ–ç‡ (%)'] = signals_table['å¤‰åŒ–ç‡ (%)'].round(2)
                signals_table['ç•°å¸¸å¼·åº¦'] = signals_table['ç•°å¸¸å¼·åº¦'].round(2)
        
        # æœ€çµ‚æ›´æ–°
        update_progress(8, 8, "åˆ†æå®Œäº†!")
        progress(1.0, desc="åˆ†æå®Œäº†!")
        
        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        status_html = f'<div class="status-success fade-in">âœ… åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼{anomalies_count}ä»¶ã®ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚</div>'
        
        return (
            plot, forecast_plot, status_html, metrics_html, 
            anomalies_df, signals_table, agent_findings, df, anomalies
        )
        
    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        print(error_traceback)
        
        error_html = f'<div class="status-error fade-in">âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}</div>'
        empty_metrics = '<div class="metrics-grid"></div>'
        
        return (
            None, None, error_html, empty_metrics,
            pd.DataFrame(), pd.DataFrame(), {}, None, None
        )

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‚’æ”¹å–„ã•ã‚ŒãŸHTMLã¨ã—ã¦æ•´å½¢
def format_agent_findings_enhanced(agent_findings):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‚’æ”¹å–„ã•ã‚ŒãŸHTMLã¨ã—ã¦æ•´å½¢"""
    # agent_findingsãŒç©ºè¾æ›¸ã€Noneã€ã¾ãŸã¯ç©ºã®DataFrameã‹ã©ã†ã‹ã‚’å®‰å…¨ã«ãƒã‚§ãƒƒã‚¯
    if (agent_findings is None or 
        (isinstance(agent_findings, dict) and len(agent_findings) == 0) or
        (hasattr(agent_findings, 'empty') and agent_findings.empty)):
        return '<div class="status-warning fade-in">âš ï¸ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æçµæœã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</div>'
    
    html = '<div class="fade-in">'
    
    # æœ€çµ‚è©•ä¾¡ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’å„ªå…ˆè¡¨ç¤º
    if "ç®¡ç†è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ" in agent_findings:
        manager_findings = agent_findings["ç®¡ç†è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"].get("findings", {})
        if manager_findings:
            html += '''
            <div class="agent-result">
                <div class="agent-header">
                    <h3>ğŸ¯ æœ€çµ‚è©•ä¾¡ãƒ»æ¨å¥¨äº‹é …</h3>
                    <span>â­ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼</span>
                </div>
                <div class="agent-content">
            '''
            
            for date, data in manager_findings.items():
                anomaly_details = data.get('anomaly_details', {})
                pct_change = anomaly_details.get('pct_change', 'N/A')
                
                html += f'''
                <div style="margin-bottom: 25px; padding: 20px; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 12px; border-left: 4px solid #28a745;">
                    <h4 style="color: #155724; margin-bottom: 15px;">ğŸ“… {date} (å¤‰åŒ–ç‡: {pct_change}%)</h4>
                    <pre style="background: white; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 0;">{data.get('final_assessment', 'N/A')}</pre>
                </div>
                '''
            
            html += '</div></div>'
    
    # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’è¡¨ç¤º
    if "ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ" in agent_findings:
        report_findings = agent_findings["ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"].get("findings", {})
        if report_findings:
            html += '''
            <div class="agent-result">
                <div class="agent-header">
                    <h3>ğŸ“‹ çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h3>
                    <span>ğŸ“Š è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµ±åˆçµæœ</span>
                </div>
                <div class="agent-content">
            '''
            
            for date, data in report_findings.items():
                anomaly_details = data.get('anomaly_details', {})
                pct_change = anomaly_details.get('pct_change', 'N/A')
                
                html += f'''
                <div style="margin-bottom: 25px; padding: 20px; background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); border-radius: 12px; border-left: 4px solid #856404;">
                    <h4 style="color: #856404; margin-bottom: 15px;">ğŸ“… {date} (å¤‰åŒ–ç‡: {pct_change}%)</h4>
                    <pre style="background: white; padding: 20px; border-radius: 8px; border: 1px solid #dee2e6; margin: 0;">{data.get('integrated_report', 'N/A')}</pre>
                </div>
                '''
            
            html += '</div></div>'
    
    # å€‹åˆ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‚‚è¡¨ç¤º
    html += '<h3 style="margin: 30px 0 20px 0; color: #495057;">ğŸ” å€‹åˆ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æè©³ç´°</h3>'
    
    agent_colors = {
        'Webæƒ…å ±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ': '#007bff',
        'çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ': '#28a745', 
        'ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ': '#ffc107'
    }
    
    agent_icons = {
        'Webæƒ…å ±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ': 'ğŸŒ',
        'çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ': 'ğŸ“š',
        'ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ': 'ğŸ”„'
    }
    
    for agent_name, findings in agent_findings.items():
        if agent_name not in ["ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", "ç®¡ç†è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"]:
            color = agent_colors.get(agent_name, '#6c757d')
            icon = agent_icons.get(agent_name, 'ğŸ¤–')
            
            html += f'''
            <details class="agent-result" style="margin-bottom: 20px;">
                <summary class="agent-header" style="background: linear-gradient(135deg, {color} 0%, {color}dd 100%);">
                    <span>{icon} {agent_name}</span>
                    <span style="font-size: 0.9em; opacity: 0.9;">ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ã‚’è¡¨ç¤º</span>
                </summary>
                <div class="agent-content">
            '''
            
            if "error" in findings:
                html += f'<div class="status-error">âŒ ã‚¨ãƒ©ãƒ¼: {findings["error"]}</div>'
            elif "findings" in findings:
                for date, data in findings["findings"].items():
                    if "llm_analysis" in data:
                        html += f'''
                        <div style="margin-bottom: 20px;">
                            <h4 style="color: {color}; margin-bottom: 10px;">ğŸ“… {date}</h4>
                            <pre style="background: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 3px solid {color}; margin-bottom: 15px;">{data['llm_analysis']}</pre>
                        '''
                        
                        # ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å ´åˆã€è¿½åŠ æŒ‡æ¨™ã‚‚è¡¨ç¤º
                        if agent_name == "ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ" and "additional_metrics" in data:
                            html += f'''
                            <div style="background: #e7f3ff; padding: 15px; border-radius: 8px; margin-top: 10px;">
                                <h5 style="color: #0056b3; margin-bottom: 10px;">ğŸ“ˆ è¿½åŠ å¸‚å ´æŒ‡æ¨™</h5>
                                <pre style="background: white; padding: 12px; border-radius: 6px; margin: 0; font-size: 0.9em;">{data['additional_metrics']}</pre>
                            </div>
                            '''
                        
                        html += '</div><hr style="border: none; border-top: 1px solid #dee2e6; margin: 20px 0;">'
            
            html += '</div></details>'
    
    html += '</div>'
    return html

# è©•ä¾¡é–¢æ•°
def run_evaluation(df, anomalies, known_anomalies_str, delay_tolerance):
    try:
        known_anomalies = [date.strip() for date in known_anomalies_str.split(',') if date.strip()]
        
        evaluator = AnomalyEvaluator(known_anomalies)
        eval_results = evaluator.evaluate(df, anomalies, int(delay_tolerance))
        
        # è©•ä¾¡æŒ‡æ¨™ã‚’DataFrameã«å¤‰æ›
        metrics_df = pd.DataFrame({
            'è©•ä¾¡æŒ‡æ¨™': ['é©åˆç‡ (Precision)', 'å†ç¾ç‡ (Recall)', 'F1ã‚¹ã‚³ã‚¢', 'FÎ²ã‚¹ã‚³ã‚¢', 'æ¤œçŸ¥é…å»¶ (æ—¥)'],
            'å€¤': [
                f"{eval_results['precision']:.4f}",
                f"{eval_results['recall']:.4f}",
                f"{eval_results['f1_score']:.4f}",
                f"{eval_results['f_beta_score']:.4f}",
                f"{eval_results['detection_delay'] if eval_results['detection_delay'] is not None else 'N/A'}"
            ],
            'èª¬æ˜': [
                'æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸ã®ã†ã¡ã€å®Ÿéš›ã«ç•°å¸¸ã ã£ãŸå‰²åˆ',
                'å®Ÿéš›ã®ç•°å¸¸ã®ã†ã¡ã€æ¤œå‡ºã§ããŸå‰²åˆ',
                'é©åˆç‡ã¨å†ç¾ç‡ã®èª¿å’Œå¹³å‡ï¼ˆç·åˆæ€§èƒ½æŒ‡æ¨™ï¼‰',
                'å†ç¾ç‡ã‚’é‡è¦–ã—ãŸç·åˆæŒ‡æ¨™ï¼ˆé‡è¦ãªç•°å¸¸ã®è¦‹é€ƒã—é˜²æ­¢ï¼‰',
                'å®Ÿéš›ã®ç•°å¸¸ç™ºç”Ÿã‹ã‚‰æ¤œå‡ºã¾ã§ã®å¹³å‡é…ã‚Œæ™‚é–“'
            ]
        })
        
        # æ··åŒè¡Œåˆ—ã‚’ä½œæˆ
        cm_df = pd.DataFrame({
            'å®Ÿéš›â†’': ['æ­£å¸¸', 'ç•°å¸¸'],
            'äºˆæ¸¬: æ­£å¸¸': [eval_results['true_negatives'], eval_results['false_negatives']],
            'äºˆæ¸¬: ç•°å¸¸': [eval_results['false_positives'], eval_results['true_positives']]
        })
        
        return metrics_df, cm_df
    
    except Exception as e:
        import traceback
        error_df = pd.DataFrame({'ã‚¨ãƒ©ãƒ¼': [str(e), traceback.format_exc()]})
        return error_df, pd.DataFrame()

# æ‰‹æ³•æ¯”è¼ƒé–¢æ•°ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ç‰ˆï¼‰
def compare_methods(df, methods, thresholds_text, known_anomalies_str):
    try:
        thresholds = [float(t.strip()) for t in thresholds_text.split(',') if t.strip()]
        known_anomalies = [date.strip() for date in known_anomalies_str.split(',') if date.strip()]
        
        evaluator = AnomalyEvaluator(known_anomalies)
        
        # ãƒ‡ãƒãƒƒã‚°: ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¡¨ç¤º
        print(f"æ‰‹æ³•æ¯”è¼ƒé–‹å§‹: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢çŠ¶ {df.shape}, ã‚«ãƒ©ãƒ : {list(df.columns)}")
        if 'Date' in df.columns and 'Close' in df.columns:
            print(f"æ—¥ä»˜ç¯„å›²: {df['Date'].min()} ï½ {df['Date'].max()}")
            print(f"ä¾¡æ ¼ç¯„å›²: {df['Close'].min():.2f} ï½ {df['Close'].max():.2f}")
        
        # ã‚«ã‚¹ã‚¿ãƒ æ¯”è¼ƒé–¢æ•°ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œç‰ˆï¼‰
        results = []
        
        for method in methods:
            for threshold in thresholds:
                try:
                    # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ãƒã‚§ãƒƒã‚¯
                    df_processed = df.copy()
                    
                    # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼ˆé–¾å€¤ã‚’ç·©å’Œï¼‰
                    if df_processed.empty or len(df_processed) < 10:  # 50 â†’ 10ã«å¤‰æ›´
                        print(f"è­¦å‘Š: ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{len(df_processed)}ä»¶ï¼‰ã€‚æ‰‹æ³• {method}, é–¾å€¤ {threshold} ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue
                    
                    # æ•°å€¤ã‚«ãƒ©ãƒ ã®ç¢ºèª
                    if 'Close' not in df_processed.columns:
                        print(f"è­¦å‘Š: 'Close'ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ‰‹æ³• {method}, é–¾å€¤ {threshold} ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue
                    
                    # NaNå€¤ã®å‡¦ç†
                    df_processed['Close'] = pd.to_numeric(df_processed['Close'], errors='coerce')
                    original_length = len(df_processed)
                    df_processed = df_processed.dropna(subset=['Close'])
                    final_length = len(df_processed)
                    
                    if final_length < 5:  # 10 â†’ 5ã«å¤‰æ›´
                        print(f"è­¦å‘Š: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ{final_length}ä»¶ã€å…ƒ: {original_length}ä»¶ï¼‰ã€‚æ‰‹æ³• {method}, é–¾å€¤ {threshold} ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue
                    
                    # æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã®å ´åˆã®è¿½åŠ ãƒã‚§ãƒƒã‚¯ï¼ˆæ¡ä»¶ã‚’ç·©å’Œï¼‰
                    if method in ['isolation_forest', 'deep_svdd']:
                        # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ100 â†’ 30ã«å¤‰æ›´ï¼‰
                        if len(df_processed) < 30:
                            print(f"è­¦å‘Š: æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³• {method} ã«ã¯æœ€ä½30ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒå¿…è¦ã§ã™ï¼ˆç¾åœ¨: {len(df_processed)}ä»¶ï¼‰ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            continue
                        
                        # å¤‰å‹•æ€§ã®ãƒã‚§ãƒƒã‚¯
                        if df_processed['Close'].std() == 0:
                            print(f"è­¦å‘Š: ãƒ‡ãƒ¼ã‚¿ã«å¤‰å‹•ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ‰‹æ³• {method}, é–¾å€¤ {threshold} ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            continue
                    
                    print(f"å®Ÿè¡Œä¸­: æ‰‹æ³• {method}, é–¾å€¤ {threshold}, ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_processed)}ä»¶")
                    
                    # ç•°å¸¸æ¤œçŸ¥å™¨ã‚’ä½œæˆï¼ˆä¿®æ­£ç‰ˆã‚’ä½¿ç”¨ï¼‰
                    if method == 'isolation_forest':
                        # ä¿®æ­£ç‰ˆIsolation Forestæ¤œå‡ºå™¨ã‚’ç›´æ¥ä½¿ç”¨
                        detector_obj = FixedIsolationForestDetector(
                            contamination=0.05,
                            n_estimators=50,  # è¨ˆç®—é‡å‰Šæ¸›
                            random_state=42
                        )
                        detected_anomalies = detector_obj.detect(df_processed)
                    elif method == 'deep_svdd':
                        # ä¿®æ­£ç‰ˆDeep SVDDæ¤œå‡ºå™¨ã‚’ç›´æ¥ä½¿ç”¨
                        detector_obj = FixedDeepSVDDDetector(
                            threshold=0.95,
                            epochs=10,  # ã‚¨ãƒãƒƒã‚¯æ•°å‰Šæ¸›ï¼ˆé«˜é€ŸåŒ–ï¼‰
                            batch_size=16,
                            random_state=42
                        )
                        detected_anomalies = detector_obj.detect(df_processed)
                    else:
                        # é€šå¸¸ã®æ¤œå‡ºå™¨ã‚’ä½¿ç”¨
                        detector = AnomalyDetector(method=method, threshold=threshold)
                        detected_anomalies = detector.detect(df_processed)
                    
                    # è©•ä¾¡ã‚’å®Ÿè¡Œ
                    eval_result = evaluator.evaluate(df_processed, detected_anomalies)
                    
                    # çµæœã‚’æ ¼ç´
                    results.append({
                        'æ¤œå‡ºæ‰‹æ³•': method,
                        'é–¾å€¤': threshold,
                        'é©åˆç‡': round(eval_result['precision'], 4),
                        'å†ç¾ç‡': round(eval_result['recall'], 4),
                        'F1ã‚¹ã‚³ã‚¢': round(eval_result['f1_score'], 4),
                        'FÎ²ã‚¹ã‚³ã‚¢': round(eval_result['f_beta_score'], 4),
                        'æ¤œçŸ¥æ•°': len(detected_anomalies),
                        'çœŸé™½æ€§': eval_result['true_positives'],
                        'å½é™½æ€§': eval_result['false_positives'],
                        'å½é™°æ€§': eval_result['false_negatives']
                    })
                    
                except Exception as method_error:
                    print(f"æ‰‹æ³• {method} (é–¾å€¤: {threshold}) ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(method_error)}")
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸæ‰‹æ³•ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
                    results.append({
                        'æ¤œå‡ºæ‰‹æ³•': method,
                        'é–¾å€¤': threshold,
                        'é©åˆç‡': 'ã‚¨ãƒ©ãƒ¼',
                        'å†ç¾ç‡': 'ã‚¨ãƒ©ãƒ¼',
                        'F1ã‚¹ã‚³ã‚¢': 'ã‚¨ãƒ©ãƒ¼',
                        'FÎ²ã‚¹ã‚³ã‚¢': 'ã‚¨ãƒ©ãƒ¼',
                        'æ¤œçŸ¥æ•°': 'ã‚¨ãƒ©ãƒ¼',
                        'çœŸé™½æ€§': 'ã‚¨ãƒ©ãƒ¼',
                        'å½é™½æ€§': 'ã‚¨ãƒ©ãƒ¼',
                        'å½é™°æ€§': 'ã‚¨ãƒ©ãƒ¼'
                    })
                    continue
        
        # çµæœã‚’DataFrameã«å¤‰æ›
        if results:
            results_df = pd.DataFrame(results)
            return results_df
        else:
            return pd.DataFrame({'ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸': ['ã™ã¹ã¦ã®æ‰‹æ³•ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚']})
        
    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        print(f"æ‰‹æ³•æ¯”è¼ƒã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(error_traceback)
        error_df = pd.DataFrame({
            'ã‚¨ãƒ©ãƒ¼': ['æ‰‹æ³•æ¯”è¼ƒä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'],
            'è©³ç´°': [str(e)],
            'æ¨å¥¨å¯¾å‡¦': ['ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèªã™ã‚‹ã‹ã€ç•°ãªã‚‹æ‰‹æ³•ã‚’è©¦ã—ã¦ãã ã•ã„']
        })
        return error_df

# Gradio UIã®ä½œæˆ
def create_gradio_ui():
    with gr.Blocks(
        title="ğŸ” ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆLLMç•°å¸¸æ¤œçŸ¥åˆ†æã‚·ã‚¹ãƒ†ãƒ ",
        css=CUSTOM_CSS,
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="green",
            neutral_hue="gray"
        )
    ) as app:
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        gr.HTML(f"""
        <div class="header fade-in">
            <h1>ğŸ” ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆLLMç•°å¸¸æ¤œçŸ¥åˆ†æã‚·ã‚¹ãƒ†ãƒ </h1>
            <p>ğŸ¤– AIé§†å‹•ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç•°å¸¸æ¤œçŸ¥ã¨åŒ…æ‹¬çš„åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </p>
        </div>
        """)
        
        # ãƒ‡ãƒ¼ã‚¿ãŠã‚ˆã³çµæœã‚’ä¿æŒã™ã‚‹çŠ¶æ…‹
        stored_df = gr.State(None)
        stored_anomalies = gr.State(None)
        
        # è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
        with gr.Group():
            gr.HTML('<div class="config-card fade-in">')
            gr.HTML('<h3>âš™ï¸ åˆ†æè¨­å®š</h3>')
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.HTML('<h4>ğŸ“Š ãƒ‡ãƒ¼ã‚¿è¨­å®š</h4>')
                    data_source = gr.Radio(
                        label="ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹",
                        choices=[("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨", "sample"), ("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "upload")],
                        value="sample",
                        info="ğŸ¯ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã¯æ­´å²çš„ãªå¸‚å ´ç•°å¸¸ãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
                    )
                    file_path = gr.File(
                        label="ğŸ“‹ æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (CSV/Excel)",
                        type="filepath",
                        visible=False
                    )
                    include_extra_indicators = gr.Checkbox(
                        label="ğŸ“ˆ è¿½åŠ æŒ‡æ¨™ã‚’å«ã‚ã‚‹ï¼ˆå‡ºæ¥é«˜ã€VIXã€ãƒ‰ãƒ«å††ï¼‰",
                        value=True,
                        info="âœ¨ ã‚ˆã‚Šè©³ç´°ãªå¸‚å ´åˆ†æã®ãŸã‚ã®è¿½åŠ ãƒ‡ãƒ¼ã‚¿"
                    )
                    
                with gr.Column(scale=1):
                    gr.HTML('<h4>ğŸ¯ ç•°å¸¸æ¤œçŸ¥è¨­å®š</h4>')
                    detection_method = gr.Dropdown(
                        label="ğŸ” æ¤œå‡ºæ–¹æ³•",
                        choices=[
                            ("Z-Scoreï¼ˆæ¨™æº–åå·®ãƒ™ãƒ¼ã‚¹ï¼‰", "z_score"),
                            ("IQRï¼ˆå››åˆ†ä½æ•°ãƒ™ãƒ¼ã‚¹ï¼‰", "iqr"),
                            ("ç§»å‹•å¹³å‡ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ä¹–é›¢ï¼‰", "moving_avg"),
                            ("Isolation Forestï¼ˆæ©Ÿæ¢°å­¦ç¿’ï¼‰", "isolation_forest"),
                            ("Deep SVDDï¼ˆæ·±å±¤å­¦ç¿’ï¼‰", "deep_svdd")
                        ],
                        value="z_score",
                        info="ğŸ“Š å„æ‰‹æ³•ã®ç‰¹å¾´ã‚’ç†è§£ã—ã¦é¸æŠã—ã¦ãã ã•ã„"
                    )
                    threshold = gr.Slider(
                        label="ğŸšï¸ æ¤œå‡ºé–¾å€¤",
                        minimum=1.0,
                        maximum=5.0,
                        value=3.0,
                        step=0.1,
                        info="âš¡ å€¤ãŒå¤§ãã„ã»ã©æ¤œå‡ºã•ã‚Œã‚‹ç•°å¸¸ãŒå°‘ãªããªã‚Šã¾ã™"
                    )

            with gr.Row():
                with gr.Column(scale=1):
                    gr.HTML('<h4>ğŸ¤– LLMè¨­å®š</h4>')
                    llm_provider = gr.Radio(
                        label="ğŸ§  LLMãƒ—ãƒ­ãƒã‚¤ãƒ€",
                        choices=[
                            ("OpenAI GPT", "openai"),
                            ("Hugging Face", "huggingface"),
                            ("Mockï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰", "mock")
                        ],
                        value="mock",
                        info="ğŸ”‘ OpenAI/HuggingFaceã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™"
                    )
                
                with gr.Column(scale=1):
                    gr.HTML('<h4>ğŸ‘¥ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š</h4>')
                    with gr.Row():
                        with gr.Column():
                            use_web_agent = gr.Checkbox(label="ğŸŒ Webæƒ…å ±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", value=True)
                            use_knowledge_agent = gr.Checkbox(label="ğŸ“š çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", value=True)
                            use_crosscheck_agent = gr.Checkbox(label="ğŸ”„ ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", value=True)
                        with gr.Column():
                            use_report_agent = gr.Checkbox(label="ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", value=True)
                            use_manager_agent = gr.Checkbox(label="ğŸ¯ ç®¡ç†è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", value=True)
            
            with gr.Row():
                with gr.Column():
                    generate_signals = gr.Checkbox(
                        label="ğŸ“ˆ å£²è²·ã‚·ã‚°ãƒŠãƒ«ã¨å°†æ¥äºˆæ¸¬ã‚’ç”Ÿæˆ",
                        value=True,
                        info="ğŸ¯ ç•°å¸¸ã‹ã‚‰æŠ•è³‡ã‚·ã‚°ãƒŠãƒ«ã‚’ç”Ÿæˆã—ã€ä¾¡æ ¼ã‚’äºˆæ¸¬ã—ã¾ã™"
                    )
                    forecast_days = gr.Slider(
                        label="ğŸ“… äºˆæ¸¬æ—¥æ•°",
                        minimum=10,
                        maximum=90,
                        value=30,
                        step=5,
                        info="ğŸ”® å°†æ¥ã®ä½•æ—¥åˆ†ã‚’äºˆæ¸¬ã™ã‚‹ã‹"
                    )
            
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å¤‰æ›´æ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
            def update_file_visibility(choice):
                return gr.update(visible=(choice == "upload"))
            
            data_source.change(fn=update_file_visibility, inputs=data_source, outputs=file_path)
            
            gr.HTML('</div>')
        
        # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³ï¼ˆå®Œç’§ãªä¸­å¤®é…ç½®ï¼‰
        gr.HTML('<div class="button-container">')
        analyze_btn = gr.Button(
            "ğŸš€ ç•°å¸¸æ¤œçŸ¥åˆ†æã‚’é–‹å§‹",
            variant="primary",
            size="lg",
            elem_classes=["primary-btn"]
        )
        gr.HTML('</div>')
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        status_display = gr.HTML("")
        metrics_display = gr.HTML("")
        
        # çµæœè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
        with gr.Group() as results_container:
            gr.HTML('<div class="results-card fade-in">')
            gr.HTML('<h3>ğŸ“Š åˆ†æçµæœ</h3>')
            
            with gr.Tabs() as result_tabs:
                # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒƒãƒˆã‚¿ãƒ–
                with gr.TabItem("ğŸ“ˆ æ™‚ç³»åˆ—åˆ†æ", id="main_plot"):
                    plot_output = gr.Plot(label="æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨ç•°å¸¸æ¤œçŸ¥çµæœ")
                
                # äºˆæ¸¬ãƒ—ãƒ­ãƒƒãƒˆã‚¿ãƒ–
                with gr.TabItem("ğŸ”® å°†æ¥äºˆæ¸¬", id="forecast"):
                    forecast_plot_output = gr.Plot(label="ä¾¡æ ¼äºˆæ¸¬ã¨ç•°å¸¸èª¿æ•´")
                
                # æ¤œå‡ºçµæœã‚¿ãƒ–
                with gr.TabItem("ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸", id="anomalies"):
                    gr.HTML('<h4>ğŸ“‹ ç•°å¸¸æ¤œçŸ¥çµæœä¸€è¦§</h4>')
                    anomaly_table = gr.DataFrame(
                        label="æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸ãƒ‡ãƒ¼ã‚¿",
                        interactive=False,
                        wrap=True
                    )
                
                # ã‚·ã‚°ãƒŠãƒ«ã‚¿ãƒ–
                with gr.TabItem("ğŸ’° æŠ•è³‡ã‚·ã‚°ãƒŠãƒ«", id="signals"):
                    gr.HTML('<h4>ğŸ“Š å£²è²·æ¨å¥¨ã‚·ã‚°ãƒŠãƒ«</h4>')
                    signals_table = gr.DataFrame(
                        label="ç•°å¸¸ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸå£²è²·ã‚·ã‚°ãƒŠãƒ«",
                        interactive=False,
                        wrap=True
                    )
                
                # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†æã‚¿ãƒ–
                with gr.TabItem("ğŸ¤– AIåˆ†æçµæœ", id="agents"):
                    gr.HTML('<h4>ğŸ§  ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç·åˆåˆ†æ</h4>')
                    agent_results = gr.HTML("")
                
                # è©•ä¾¡ã‚¿ãƒ–
                with gr.TabItem("ğŸ“Š æ€§èƒ½è©•ä¾¡", id="evaluation"):
                    gr.HTML('<div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); padding: 20px; border-radius: 12px; margin-bottom: 20px;">')
                    gr.HTML('<h4>ğŸ¯ ç•°å¸¸æ¤œçŸ¥ç²¾åº¦ã®è©•ä¾¡</h4>')
                    gr.HTML('<p>ğŸ“ˆ æ—¢çŸ¥ã®ç•°å¸¸æ—¥ä»˜ã‚’å…¥åŠ›ã—ã¦ã€æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ€§èƒ½ã‚’å®šé‡çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚</p>')
                    gr.HTML('</div>')
                    
                    with gr.Row():
                        with gr.Column():
                            known_anomalies = gr.Textbox(
                                label="ğŸ“… æ—¢çŸ¥ã®ç•°å¸¸æ—¥ä»˜ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€YYYY-MM-DDå½¢å¼ï¼‰",
                                placeholder="ä¾‹: 1987-10-19, 2008-10-13, 2020-03-16",
                                value="1987-10-19, 2008-10-13, 2020-03-16",
                                info="ğŸ¯ è©•ä¾¡ç”¨ã®æ­£è§£ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™"
                            )
                        with gr.Column():
                            delay_tolerance = gr.Number(
                                label="â±ï¸ æ¤œçŸ¥é…å»¶è¨±å®¹å€¤ï¼ˆæ—¥æ•°ï¼‰",
                                value=0,
                                minimum=0,
                                step=1,
                                info="ğŸ” æ¤œçŸ¥ãŒä½•æ—¥é…ã‚Œã¦ã‚‚æ­£è§£ã¨ã¿ãªã™ã‹"
                            )
                    
                    with gr.Row():
                        evaluate_btn = gr.Button("ğŸ“Š è©•ä¾¡å®Ÿè¡Œ", variant="secondary", elem_classes=["secondary-btn"])
                        compare_btn = gr.Button("âš–ï¸ æ‰‹æ³•æ¯”è¼ƒ", variant="secondary", elem_classes=["secondary-btn"])
                    
                    with gr.Accordion("ğŸ“š è©•ä¾¡æŒ‡æ¨™ã®è©³ç´°èª¬æ˜", open=False):
                        gr.HTML("""
                        <div style="background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 10px 0;">
                            <h5>ğŸ“Š æ€§èƒ½æŒ‡æ¨™ã«ã¤ã„ã¦</h5>
                            <ul style="line-height: 1.8;">
                                <li><strong>ğŸ¯ é©åˆç‡ï¼ˆPrecisionï¼‰:</strong> æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸ã®ã†ã¡ã€å®Ÿéš›ã«ç•°å¸¸ã ã£ãŸå‰²åˆã€‚å€¤ãŒé«˜ã„ã»ã©èª¤æ¤œçŸ¥ãŒå°‘ãªã„ã€‚</li>
                                <li><strong>ğŸ” å†ç¾ç‡ï¼ˆRecallï¼‰:</strong> å®Ÿéš›ã®ç•°å¸¸ã®ã†ã¡ã€æ¤œå‡ºã§ããŸå‰²åˆã€‚å€¤ãŒé«˜ã„ã»ã©è¦‹é€ƒã—ãŒå°‘ãªã„ã€‚</li>
                                <li><strong>âš–ï¸ F1ã‚¹ã‚³ã‚¢:</strong> é©åˆç‡ã¨å†ç¾ç‡ã®èª¿å’Œå¹³å‡ã€‚ç·åˆçš„ãªæ€§èƒ½æŒ‡æ¨™ã€‚</li>
                                <li><strong>ğŸ“ˆ FÎ²ã‚¹ã‚³ã‚¢:</strong> å†ç¾ç‡ã‚’ã‚ˆã‚Šé‡è¦–ã—ãŸæŒ‡æ¨™ï¼ˆÎ²=2ï¼‰ã€‚é‡å¤§ãªç•°å¸¸ã‚’è¦‹é€ƒã—ãŸããªã„å ´åˆã«æœ‰ç”¨ã€‚</li>
                                <li><strong>â±ï¸ æ¤œçŸ¥é…å»¶:</strong> å®Ÿéš›ã®ç•°å¸¸ç™ºç”Ÿã‹ã‚‰æ¤œå‡ºã¾ã§ã®å¹³å‡é…ã‚Œæ™‚é–“ï¼ˆæ—¥æ•°ï¼‰ã€‚</li>
                            </ul>
                        </div>
                        """)
                    
                    gr.HTML('<h5>ğŸ“ˆ åŸºæœ¬è©•ä¾¡æŒ‡æ¨™</h5>')
                    evaluation_metrics = gr.DataFrame(
                        label="æ€§èƒ½è©•ä¾¡çµæœ",
                        interactive=False,
                        wrap=True
                    )
                    
                    gr.HTML('<h5>ğŸ“Š æ··åŒè¡Œåˆ—ï¼ˆäºˆæ¸¬ç²¾åº¦ã®è©³ç´°ï¼‰</h5>')
                    confusion_matrix_df = gr.DataFrame(
                        label="æ··åŒè¡Œåˆ—",
                        interactive=False
                    )
                    
                    gr.HTML('<h5>âš–ï¸ è¤‡æ•°æ‰‹æ³•ãƒ»é–¾å€¤ã®æ¯”è¼ƒåˆ†æ</h5>')
                    with gr.Row():
                        methods_select = gr.CheckboxGroup(
                            label="ğŸ” æ¯”è¼ƒã™ã‚‹æ¤œå‡ºæ‰‹æ³•",
                            choices=[
                                ("Z-Score", "z_score"),
                                ("IQR", "iqr"), 
                                ("ç§»å‹•å¹³å‡", "moving_avg"),
                                ("Isolation Forest", "isolation_forest"),
                                ("Deep SVDD", "deep_svdd")
                            ],
                            value=["z_score", "iqr", "moving_avg"],
                            info="ğŸ“‹ è¤‡æ•°ã®æ‰‹æ³•ã‚’é¸æŠã—ã¦æ€§èƒ½ã‚’æ¯”è¼ƒã§ãã¾ã™"
                        )
                        thresholds_text = gr.Textbox(
                            label="ğŸšï¸ æ¯”è¼ƒã™ã‚‹é–¾å€¤ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
                            value="2.0, 2.5, 3.0, 3.5",
                            placeholder="ä¾‹: 2.0, 2.5, 3.0, 3.5",
                            info="ğŸ“Š ç•°ãªã‚‹é–¾å€¤ã§ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¾ã™"
                        )
                    
                    comparison_results = gr.DataFrame(
                        label="æ‰‹æ³•æ¯”è¼ƒçµæœ",
                        interactive=False,
                        wrap=True
                    )
            
            gr.HTML('</div>')
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        def handle_analyze_click(*args):
            return run_analysis(*args)
        
        def handle_results_display(plot, forecast_plot, status, metrics, anomalies_table, signals_table, findings, df, anomalies):
            agent_html = format_agent_findings_enhanced(findings)
            return (
                plot, forecast_plot, status, metrics,
                anomalies_table, signals_table, agent_html, df, anomalies
            )
        
        def handle_evaluate(stored_df, stored_anomalies, known_anomalies_str, delay_tolerance):
            if (stored_df is None or 
                stored_anomalies is None or 
                (hasattr(stored_anomalies, 'empty') and stored_anomalies.empty)):
                return pd.DataFrame({'âš ï¸ æ³¨æ„': ['å…ˆã«ç•°å¸¸æ¤œçŸ¥åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„']}), pd.DataFrame()
            
            return run_evaluation(stored_df, stored_anomalies, known_anomalies_str, delay_tolerance)
        
        def handle_compare(stored_df, methods, thresholds_text, known_anomalies_str):
            if stored_df is None or (hasattr(stored_df, 'empty') and stored_df.empty):
                return pd.DataFrame({'âš ï¸ æ³¨æ„': ['å…ˆã«ç•°å¸¸æ¤œçŸ¥åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„']})
            
            return compare_methods(stored_df, methods, thresholds_text, known_anomalies_str)
            
            return run_evaluation(stored_df, stored_anomalies, known_anomalies_str, delay_tolerance)
        
        def handle_compare(stored_df, methods, thresholds_text, known_anomalies_str):
            if stored_df is None:
                error_df = pd.DataFrame({'âš ï¸ æ³¨æ„': ['å…ˆã«ç•°å¸¸æ¤œçŸ¥åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„']})
                return error_df
            
            return compare_methods(stored_df, methods, thresholds_text, known_anomalies_str)
        
        stored_agent_findings = gr.State(None)

        # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆ
        analyze_btn.click(
            fn=handle_analyze_click,
            inputs=[
                data_source, file_path, detection_method, threshold, llm_provider,
                use_web_agent, use_knowledge_agent, use_crosscheck_agent,
                use_report_agent, use_manager_agent, include_extra_indicators,
                generate_signals, forecast_days
            ],
            outputs=[
                plot_output, forecast_plot_output, status_display, metrics_display,
                anomaly_table, signals_table,
                stored_agent_findings,   # â† agent_findings ã‚’ã“ã“ã«
                stored_df,               # â† df
                stored_anomalies         # â† anomalies
            ]
        ).then(
            fn=handle_results_display,
            inputs=[
                plot_output, forecast_plot_output, status_display, metrics_display,
                anomaly_table, signals_table,
                stored_agent_findings,   # findings
                stored_df,               # df
                stored_anomalies         # anomalies
            ],
            outputs=[
                plot_output, forecast_plot_output, status_display, metrics_display,
                anomaly_table, signals_table,
                agent_results,           # HTML ã¸æç”»
                stored_df,
                stored_anomalies
            ]
        )
        
        # è©•ä¾¡ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆ
        evaluate_btn.click(
            fn=handle_evaluate,
            inputs=[stored_df, stored_anomalies, known_anomalies, delay_tolerance],
            outputs=[evaluation_metrics, confusion_matrix_df]
        )
        
        # æ‰‹æ³•æ¯”è¼ƒãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆ
        compare_btn.click(
            fn=handle_compare,
            inputs=[stored_df, methods_select, thresholds_text, known_anomalies],
            outputs=comparison_results
        )
    
    return app

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if __name__ == "__main__":
    app = create_gradio_ui()
    app.queue().launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7861,
        show_error=True
    )
